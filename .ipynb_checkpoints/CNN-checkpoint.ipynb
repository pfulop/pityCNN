{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def block(inputs, filters):\n",
    "    conv1 = tf.layers.conv2d(inputs,\n",
    "                            filters,\n",
    "                            4,\n",
    "                            padding=\"same\",\n",
    "                            activation=\"relu\",\n",
    "                            name=\"conv{}_1\".format(filters))\n",
    "    conv2 = tf.layers.conv2d(conv1,\n",
    "                            filters,\n",
    "                            4,\n",
    "                            padding=\"same\",\n",
    "                            activation=\"relu\",\n",
    "                            name=\"conv{}_2\".format(filters))\n",
    "    conv3 = tf.layers.conv2d(conv2,\n",
    "                            filters,\n",
    "                            4,\n",
    "                            padding=\"same\",\n",
    "                            activation=\"relu\",\n",
    "                            name=\"conv{}_3\".format(filters))\n",
    "    pool = tf.layers.max_pooling2d(conv3,\n",
    "                            pool_size=2,\n",
    "                            strides=2,\n",
    "                            name=\"pool{}\".format(filters))\n",
    "    return pool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def architecture(inputs, filter_size, output_size):\n",
    "    \n",
    "    with tf.variable_scope('CovNet'):\n",
    "        for filter_size in enumerate(filter_size):\n",
    "            with tf.name_scope(\"conv-maxpool-%s\" % filter_size):\n",
    "                      inputs = block(inputs, filter_size)\n",
    "        \n",
    "        with tf.name_scope(\"conv-dense\"):\n",
    "            dense1 = tf.layers.dense(\n",
    "                inputs,\n",
    "                4096,\n",
    "                activation='relu',\n",
    "                name='dense1',\n",
    "            )\n",
    "            dense2 = tf.layers.dense(\n",
    "                dense1,\n",
    "                4096,\n",
    "                activation='relu',\n",
    "                name='dense2',\n",
    "            )\n",
    "            net = tf.layers.dense(\n",
    "                dense2,\n",
    "                output_size,\n",
    "                activation='softmax',\n",
    "                name='softmax',\n",
    "            )\n",
    "\n",
    "    return net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_train_op_fn(loss, params):\n",
    "    return tf.contrib.layers.optimize_loss(\n",
    "        loss=loss,\n",
    "        global_step=tf.contrib.framework.get_global_step(),\n",
    "        optimizer=tf.train.AdamOptimizer,\n",
    "        learning_rate=params.learning_rate\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_eval_metric_ops(labels, predictions):\n",
    "    return {\n",
    "        'Accuracy': tf.metrics.accuracy(\n",
    "            labels=labels,\n",
    "            predictions=predictions,\n",
    "            name='accuracy')\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_fn(features, labels, mode, params):\n",
    "    filter_size = [64,128,256,512,512]    \n",
    "    output_size = labels.shape\n",
    "    is_trainig = mode == ModeKeys.TRAIN\n",
    "    logits = architecture(features, filter_size, output_size)\n",
    "    predictions = tf.argmax(logits, axis = -1)\n",
    "    \n",
    "    loss = None\n",
    "    train_op = None\n",
    "    eval_metric_ops = {}\n",
    "    if mode != ModeKeys.INFER:\n",
    "        loss = tf.losses.log_loss(\n",
    "            labels=tf.cast(labels, tf.int32),\n",
    "            logits=logits)\n",
    "        train_op = get_train_op_fn(loss, params)\n",
    "        eval_metric_ops = get_eval_metric_ops(labels, predictions)\n",
    "    return tf.estimator.EstimatorSpec(\n",
    "        mode=mode,\n",
    "        predictions=predictions,\n",
    "        loss=loss,\n",
    "        train_op=train_op,\n",
    "        eval_metric_ops=eval_metric_ops\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_estimator(run_config, params):\n",
    "    return tf.estimator.Estimator(\n",
    "        model_fn=model_fn,  # First-class function\n",
    "        params=params,  # HParams\n",
    "        config=run_config  # RunConfig\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class IteratorInitializerHook(tf.train.SessionRunHook):\n",
    "\n",
    "    def __init__(self):\n",
    "        super(IteratorInitializerHook, self).__init__()\n",
    "        self.iterator_initializer_func = None\n",
    "\n",
    "    def after_create_session(self, session, coord):\n",
    "        self.iterator_initializer_func(session)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_input_fn(file_pattern, batch_size, labels, num_epochs=None, shuffle=False):\n",
    "\n",
    "    def _input_fn():\n",
    "        height, width, channels = [256, 256, 3]\n",
    "        with tf.name_scope('input'):\n",
    "            filenames_tensor = tf.train.match_filenames_once(file_pattern)\n",
    "            filename_queue = tf.train.string_input_producer(\n",
    "                filenames_tensor,\n",
    "                num_epochs=num_epochs,\n",
    "                shuffle=shuffle)\n",
    "\n",
    "            reader = tf.WholeFileReader()\n",
    "            filename, contents = reader.read(filename_queue)\n",
    "\n",
    "            image = tf.image.decode_jpeg(contents, channels=channels)\n",
    "            image = tf.image.resize_image_with_crop_or_pad(image, height, width)\n",
    "            image_batch, filname_batch = tf.train.batch(\n",
    "                [image, filename],\n",
    "                batch_size,\n",
    "                num_threads=4,\n",
    "                capacity=50000)\n",
    "\n",
    "            # Converts image from uint8 to float32 and rescale from 0..255 => 0..1\n",
    "            # Rescale from 0..1 => -1..1 so that the \"center\" of the image range is roughly 0.\n",
    "            image_batch = tf.to_float(image_batch) / 255\n",
    "            image_batch = (image_batch * 2) - 1\n",
    "\n",
    "            features = {\n",
    "                \"image\": image_batch,\n",
    "                \"filename\": filname_batch\n",
    "            }\n",
    "\n",
    "            labels = {\n",
    "                \"image\": labels\n",
    "            }\n",
    "            \n",
    "            return features, labels\n",
    "    return _input_fn\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-2-024a2ef32454>, line 6)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-2-024a2ef32454>\"\u001b[0;36m, line \u001b[0;32m6\u001b[0m\n\u001b[0;31m    128, labels ,1, True)\u001b[0m\n\u001b[0m      ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "def experiment_fn(run_config, params):\n",
    "    DATA_PATH = '/run/media/backman/yay/dogbreed/'\n",
    "    run_config = run_config.replace(save_checkpoints_steps=params.min_eval_frequency)\n",
    "    estimator = get_estimator(run_config, params)\n",
    "    train_input_fn = generate_input_fn(DATA_PATH+'train/*.jpg',\n",
    "       128, labels ,1, True)\n",
    "    eval_input_fn, eval_input_hook = generate_input_fn(DATA_PATH+'valid/*.jpg',\n",
    "       128, labels)\n",
    "    \n",
    "    experiment = tf.contrib.learn.Experiment(\n",
    "        estimator=estimator,  # Estimator\n",
    "        train_input_fn=train_input_fn,  # First-class function\n",
    "        eval_input_fn=eval_input_fn,  # First-class function\n",
    "        train_steps=params.train_steps,  # Minibatch steps\n",
    "        min_eval_frequency=params.min_eval_frequency,  # Eval frequency\n",
    "        train_monitors=[train_input_hook],  # Hooks for training\n",
    "        eval_hooks=[eval_input_hook],  # Hooks for evaluation\n",
    "        eval_steps=None  # Use evaluation feeder until its empty\n",
    "    )\n",
    "    return experiment\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"ReaderReadV2_2:0\", shape=(), dtype=string) Tensor(\"DecodeJpeg:0\", shape=(?, ?, ?), dtype=uint8)\n"
     ]
    }
   ],
   "source": [
    "DATA_PATH = '/Users/fulop/Downloads/test/train/dogs/'\n",
    "filename_queue = tf.train.string_input_producer(tf.train.match_filenames_once(\"{}*.jpg\".format(DATA_PATH)))\n",
    "reader = tf.WholeFileReader()\n",
    "key, file = reader.read(filename_queue)\n",
    "image = tf.image.decode_jpeg(file)\n",
    "\n",
    "print(key, image);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
