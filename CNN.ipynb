{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def block(inputs, filters):\n",
    "    conv1 = tf.layers.conv2d(inputs,\n",
    "                            filters,\n",
    "                            4,\n",
    "                            padding=\"same\",\n",
    "                            activation=\"relu\",\n",
    "                            name=\"conv{}_1\".format(filters))\n",
    "    conv2 = tf.layers.conv2d(conv1,\n",
    "                            filters,\n",
    "                            4,\n",
    "                            padding=\"same\",\n",
    "                            activation=\"relu\",\n",
    "                            name=\"conv{}_2\".format(filters))\n",
    "    conv3 = tf.layers.conv2d(conv2,\n",
    "                            filters,\n",
    "                            4,\n",
    "                            padding=\"same\",\n",
    "                            activation=\"relu\",\n",
    "                            name=\"conv{}_3\".format(filters))\n",
    "    pool = tf.layers.max_pooling2d(conv3,\n",
    "                            pool_size=2,\n",
    "                            strides=2,\n",
    "                            name=\"pool{}\".format(filters))\n",
    "    return pool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def architecture(inputs, filter_size, output_size):\n",
    "    \n",
    "    with tf.variable_scope('CovNet'):\n",
    "        for filter_size in enumerate(filter_size):\n",
    "            with tf.name_scope(\"conv-maxpool-%s\" % filter_size):\n",
    "                      inputs = block(inputs, filter_size)\n",
    "        \n",
    "        with tf.name_scope(\"conv-dense\"):\n",
    "            dense1 = tf.layers.dense(\n",
    "                inputs,\n",
    "                4096,\n",
    "                activation='relu',\n",
    "                name='dense1',\n",
    "            )\n",
    "            dense2 = tf.layers.dense(\n",
    "                dense1,\n",
    "                4096,\n",
    "                activation='relu',\n",
    "                name='dense2',\n",
    "            )\n",
    "            net = tf.layers.dense(\n",
    "                dense2,\n",
    "                output_size,\n",
    "                activation='softmax',\n",
    "                name='softmax',\n",
    "            )\n",
    "\n",
    "    return net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_train_op_fn(loss, params):\n",
    "    return tf.contrib.layers.optimize_loss(\n",
    "        loss=loss,\n",
    "        global_step=tf.contrib.framework.get_global_step(),\n",
    "        optimizer=tf.train.AdamOptimizer,\n",
    "        learning_rate=params.learning_rate\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_eval_metric_ops(labels, predictions):\n",
    "    return {\n",
    "        'Accuracy': tf.metrics.accuracy(\n",
    "            labels=labels,\n",
    "            predictions=predictions,\n",
    "            name='accuracy')\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_fn(features, labels, mode, params):\n",
    "    filter_size = [64,128,256,512,512]    \n",
    "    output_size = labels.shape\n",
    "    is_trainig = mode == ModeKeys.TRAIN\n",
    "    logits = architecture(features, filter_size, output_size)\n",
    "    predictions = tf.argmax(logits, axis = -1)\n",
    "    \n",
    "    loss = None\n",
    "    train_op = None\n",
    "    eval_metric_ops = {}\n",
    "    if mode != ModeKeys.INFER:\n",
    "        loss = tf.losses.log_loss(\n",
    "            labels=tf.cast(labels, tf.int32),\n",
    "            logits=logits)\n",
    "        train_op = get_train_op_fn(loss, params)\n",
    "        eval_metric_ops = get_eval_metric_ops(labels, predictions)\n",
    "    return tf.estimator.EstimatorSpec(\n",
    "        mode=mode,\n",
    "        predictions=predictions,\n",
    "        loss=loss,\n",
    "        train_op=train_op,\n",
    "        eval_metric_ops=eval_metric_ops\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_estimator(run_config, params):\n",
    "    return tf.estimator.Estimator(\n",
    "        model_fn=model_fn,  # First-class function\n",
    "        params=params,  # HParams\n",
    "        config=run_config  # RunConfig\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class IteratorInitializerHook(tf.train.SessionRunHook):\n",
    "\n",
    "    def __init__(self):\n",
    "        super(IteratorInitializerHook, self).__init__()\n",
    "        self.iterator_initializer_func = None\n",
    "\n",
    "    def after_create_session(self, session, coord):\n",
    "        self.iterator_initializer_func(session)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_train_inputs(batch_size, images, labels):\n",
    "    \n",
    "    iterator_initializer_hook = IteratorInitializerHook()\n",
    "\n",
    "    def train_inputs():\n",
    "        with tf.name_scope('Training_data'):\n",
    "            # Get Mnist data\n",
    "            images = images.reshape([-1, 28, 28, 1])\n",
    "            # Define placeholders\n",
    "            images_placeholder = tf.placeholder(\n",
    "                images.dtype, images.shape)\n",
    "            labels_placeholder = tf.placeholder(\n",
    "                labels.dtype, labels.shape)\n",
    "            # Build dataset iterator\n",
    "            dataset = tf.contrib.data.Dataset.from_tensor_slices(\n",
    "                (images_placeholder, labels_placeholder))\n",
    "            dataset = dataset.repeat(None)  # Infinite iterations\n",
    "            dataset = dataset.shuffle(buffer_size=10000)\n",
    "            dataset = dataset.batch(batch_size)\n",
    "            iterator = dataset.make_initializable_iterator()\n",
    "            next_example, next_label = iterator.get_next()\n",
    "            # Set runhook to initialize iterator\n",
    "            iterator_initializer_hook.iterator_initializer_func = \\\n",
    "                lambda sess: sess.run(\n",
    "                    iterator.initializer,\n",
    "                    feed_dict={images_placeholder: images,\n",
    "                               labels_placeholder: labels})\n",
    "            # Return batched (features, labels)\n",
    "            return next_example, next_label\n",
    "\n",
    "    # Return function and hook\n",
    "    return train_inputs, iterator_initializer_hook\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def experiment_fn(run_config, params):\n",
    "    \n",
    "    run_config = run_config.replace(save_checkpoints_steps=params.min_eval_frequency)\n",
    "    estimator = get_estimator(run_config, params)\n",
    "    \n",
    "    filename_Que = tf.train.string_input_producer(tf.train.match_filenames_once(\"./images/*.jpg\"))\n",
    "    \n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
